{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "720e19e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим нужные библиотеки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import plt, mpl\n",
    "import seaborn as sns\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "import math\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "# Чистка отклонений\n",
    "import scipy.stats as stats\n",
    "# Уберем warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Тематическое моделирование\n",
    "import gensim\n",
    "\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ba30eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тематическое моделирование\n",
    "#test_df = them_topic(test_df, features='features')\n",
    "#train_df = them_topic(train_df, features='features')\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.read_json('train.json')\n",
    "test_df = pd.read_json('test.json')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Чистка широты и долготы\n",
    "train_df[\"longitude\"]=train_df[\"longitude\"].apply(lambda x:-73.75 if x>=-73.75 else x)\n",
    "test_df[\"longitude\"]=test_df[\"longitude\"].apply(lambda x:-74.05 if x<=-74.05 else x)\n",
    "train_df[\"latitude\"]=train_df[\"latitude\"].apply(lambda x:40.4 if x<=40.4 else x)\n",
    "test_df[\"latitude\"]=test_df[\"latitude\"].apply(lambda x:40.9 if x>=40.9 else x)\n",
    "\n",
    "mean_price = int(train_df['price'].mean())\n",
    "test_df.loc[test_df['price']<200,'price'] = mean_price\n",
    "train_df.loc[train_df['price']<200,'price'] = mean_price\n",
    "# Метапризнак предсказ цены на основе координат\n",
    "#X_train_coor = train_df[['latitude', 'longitude']]\n",
    "#X_test_coor = test_df[['latitude', 'longitude']]\n",
    "\n",
    "#y_train_price = train_df.price\n",
    "#y_test_price = test_df.price\n",
    "\n",
    "#neigh_train = KNeighborsRegressor(n_neighbors=2)\n",
    "#neigh_train.fit(X_train_coor, y_train_price)\n",
    "\n",
    "#neigh_test = KNeighborsRegressor(n_neighbors=2)\n",
    "#neigh_test.fit(X_test_coor, y_test_price)\n",
    "\n",
    "#train_df['price_comparison'] = train_df['price'] /  neigh_train.predict(X_train_coor)\n",
    "#test_df['price_comparison'] = test_df['price'] /  neigh_test.predict(X_test_coor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_df['features'] = [','.join(map(str, i)) for i in train_df['features']]\n",
    "test_df['features'] = [','.join(map(str, i)) for i in test_df['features']]\n",
    "\n",
    "\n",
    "\n",
    "# Функция расчета расстояния от манхэттэна\n",
    "def distance_pair(lat1, lon1, lat2, lon2):\n",
    "    # Перевод в радианы\n",
    "    p = 0.017453292519943295     #Pi/180\n",
    "    haver_formula = 0.5 - np.cos((lat2 - lat1) * p)/2 +  np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n",
    "    d_2_point = 6367 *2 * np.arcsin(np.sqrt(haver_formula)) \n",
    "    return d_2_point\n",
    "distance_pairs = np.vectorize(distance_pair)\n",
    "\n",
    "# Расстояние от финансового центра\n",
    "train_df['distance_manh'] = distance_pairs(train_df.latitude, train_df.longitude, 40.70858733058446, -74.01098113951349)\n",
    "test_df['distance_manh'] = distance_pairs(test_df.latitude, test_df.longitude, 40.70858733058446, -74.01098113951349)\n",
    "\n",
    "\n",
    "# Расстояние от центр парка\n",
    "train_df['distance_central_park'] = distance_pairs(train_df.latitude, train_df.longitude, 40.77897128595648, -73.96656147253005)\n",
    "test_df['distance_central_park'] = distance_pairs(test_df.latitude, test_df.longitude, 40.77897128595648, -73.96656147253005)\n",
    "\n",
    "# Расстояние от  Бронкс\n",
    "train_df['bronx'] = distance_pairs(train_df.latitude, train_df.longitude, 40.84928609864644, -73.88844362698887)\n",
    "test_df['bronx'] = distance_pairs(test_df.latitude, test_df.longitude, 40.84928609864644, -73.88844362698887)\n",
    "\n",
    "# Расстояние от Район Queens\n",
    "\n",
    "train_df['queens'] = distance_pairs(train_df.latitude, train_df.longitude, 40.747803602867066, -73.90170458998642)\n",
    "test_df['queens'] = distance_pairs(test_df.latitude, test_df.longitude, 40.747803602867066, -73.90170458998642)\n",
    "\n",
    "# Расстояние от Район Brooklin кладбище\n",
    "\n",
    "train_df['brooklin_cometery'] = distance_pairs(train_df.latitude, train_df.longitude, 40.68822862016868, -73.87615328604328)\n",
    "test_df['brooklin_cometery'] = distance_pairs(test_df.latitude, test_df.longitude, 40.68822862016868, -73.87615328604328)\n",
    "\n",
    "# Расстояние от Район Brooklin\n",
    "train_df['brooklin'] = distance_pairs(train_df.latitude, train_df.longitude, 40.62506864788317, -73.96786745767038)\n",
    "test_df['brooklin'] = distance_pairs(test_df.latitude, test_df.longitude, 40.62506864788317, -73.96786745767038)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Кластеризация координат\n",
    "geo = ['latitude', 'longitude']\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "\n",
    "# Метки кластеров внесем в переменную clusters\n",
    "train_df['clusters'] = kmeans.fit(train_df[geo]).labels_\n",
    "test_df['clusters'] = kmeans.fit(test_df[geo]).labels_\n",
    "\n",
    "\n",
    "#test_df = test.copy()\n",
    "\n",
    "\n",
    "train_df['photos'] = train_df['photos'].apply(len)\n",
    "test_df['photos'] = test_df['photos'].apply(len)\n",
    "\n",
    "# Число признаков\n",
    "train_df['num_features'] = train_df['features'].apply(len)\n",
    "test_df['num_features'] = test_df['features'].apply(len)\n",
    "\n",
    "# Количество слов\n",
    "train_df['num_description_words'] = train_df['description'].apply(lambda x: len(x.split(\" \")))\n",
    "test_df['num_description_words'] = test_df['description'].apply(lambda x: len(x.split(\" \")))\n",
    "\n",
    "\n",
    "# Даты\n",
    "train_df['created'] = pd.to_datetime(train_df['created'])\n",
    "test_df['created'] = pd.to_datetime(test_df['created'])\n",
    "\n",
    "# Извлекаем время\n",
    "train_df['created_year'] = train_df['created'].dt.year\n",
    "test_df['created_year'] = test_df['created'].dt.year\n",
    "train_df['created_month'] = train_df['created'].dt.month\n",
    "test_df['created_month'] = test_df['created'].dt.month\n",
    "train_df['created_day'] = train_df['created'].dt.day\n",
    "test_df['created_day'] = test_df['created'].dt.day\n",
    "train_df['created_hour'] = train_df['created'].dt.hour\n",
    "test_df['created_hour'] = test_df['created'].dt.hour\n",
    "\n",
    "\n",
    "\n",
    "# Фичи по ванной и спальням\n",
    "# Разл в комнатах\n",
    "train_df['room_difference'] = train_df['bedrooms'] - train_df['bathrooms']\n",
    "test_df['room_difference'] = test_df['bedrooms'] - test_df['bathrooms']\n",
    "# Общее количество\n",
    "train_df['total_rooms'] = train_df['bedrooms'] + train_df['bathrooms']\n",
    "test_df['total_rooms'] = test_df['bedrooms'] + test_df['bathrooms']\n",
    "# Цена 1 добавляется чтобы исключить деление на ноль\n",
    "train_df['price_per_room'] = train_df['price'] / (train_df['total_rooms'] + 1)\n",
    "test_df['price_per_room'] = test_df['price'] / (test_df['total_rooms'] + 1)\n",
    "# Цена за спальню\n",
    "train_df['price_per_bedroom'] =train_df['price']/(train_df['bedrooms'] + 1)\n",
    "test_df['price_per_bedroom'] =test_df['price']/(test_df['bedrooms'] +1)\n",
    "\n",
    "# Цена за ванную\n",
    "train_df['price_per_bathroom'] =train_df['price']/(train_df['bathrooms'] +1)\n",
    "test_df['price_per_bathroom'] =test_df['price']/(test_df['bathrooms'] +1)\n",
    "\n",
    "# Близость к метро\n",
    "subway = pd.read_csv('NYC_Transit_Subway_Entrance_And_Exit_Data.csv') # сторонние данные\n",
    "subway = subway[['Station Name', 'Station Latitude', 'Station Longitude']]\n",
    "subway = subway.groupby(['Station Name']).mean().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Функция минимального расстояния от метро\n",
    "def get_subway_distance(location):\n",
    "    distances = distance_pairs(location[0], location[1], subway['Station Latitude'], subway['Station Longitude'])    \n",
    "    return min(distances)\n",
    "\n",
    "# Расчет минимальной дистанции до метро\n",
    "train_df['location'] = train_df[['latitude', 'longitude']].values.tolist()\n",
    "test_df['location'] = test_df[['latitude', 'longitude']].values.tolist()\n",
    "\n",
    "train_df['subway_distance'] = train_df['location'].apply(get_subway_distance)\n",
    "test_df['subway_distance'] = test_df['location'].apply(get_subway_distance)\n",
    "\n",
    "\n",
    "# Плотность по координатам https://www.kaggle.com/code/maheshak04/rh004\n",
    "train_df[\"pos\"] = train_df.longitude.round(3).astype(str) + '_' + train_df.latitude.round(3).astype(str)\n",
    "test_df[\"pos\"] = test_df.longitude.round(3).astype(str) + '_' + test_df.latitude.round(3).astype(str)\n",
    "\n",
    "vals = train_df['pos'].value_counts()\n",
    "dvals = vals.to_dict()\n",
    "train_df[\"density\"] = train_df['pos'].apply(lambda x: dvals.get(x, vals.min()))\n",
    "test_df[\"density\"] = test_df['pos'].apply(lambda x: dvals.get(x, vals.min()))\n",
    "\n",
    "\n",
    "\n",
    "# Фичи отсюда https://www.kaggle.com/code/slavik0505/kernel43aae13b62\n",
    "train_df[\"listing_id1\"] = train_df[\"listing_id\"] - 68119576.0\n",
    "test_df[\"listing_id1\"] =  test_df[\"listing_id\"] - 68119576.0\n",
    "\n",
    "train_df[\"total_days\"] =   (train_df[\"created_month\"] -4.0)*30 + train_df[\"created_day\"] +  train_df[\"created_hour\"] /25.0\n",
    "test_df[\"total_days\"] =(test_df[\"created_month\"] -4.0)*30 + test_df[\"created_day\"] +  test_df[\"created_hour\"] /25.0        \n",
    "train_df[\"diff_rank\"]= train_df[\"total_days\"]/train_df[\"listing_id1\"]\n",
    "test_df[\"diff_rank\"]= test_df[\"total_days\"]/test_df[\"listing_id1\"]\n",
    "\n",
    "# Фича из фото нужно скачать торрент файл\n",
    "df_time = pd.read_csv('listing_image_time.csv')\n",
    "train_df = train_df.merge(df_time, how='left', on='listing_id', suffixes=('', '_remove'))\n",
    "test_df = test_df.merge(df_time, how='left', on='listing_id', suffixes=('', '_remove'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "14bef4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фичи отсюда https://www.kaggle.com/code/slavik0505/kernel43aae13b62\n",
    "train_df[\"price0\"] = (train_df[\"price\"]%10).astype(int)\n",
    "test_df[\"price0\"] = (test_df[\"price\"]%10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0c4e01ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фичи отсюда https://www.kaggle.com/code/slavik0505/kernel43aae13b62\n",
    "train_df[\"price_latitude\"] = (train_df[\"price\"])/ (train_df[\"latitude\"]+1.0)\n",
    "test_df[\"price_latitude\"] =  (test_df[\"price\"])/ (test_df[\"latitude\"]+1.0)\n",
    "\n",
    "train_df[\"price_longtitude\"] = (train_df[\"price\"])/ (train_df[\"longitude\"]-1.0)\n",
    "test_df[\"price_longtitude\"] =  (test_df[\"price\"])/ (test_df[\"longitude\"]-1.0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "c6467f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_feat = ['bathrooms', 'bedrooms', 'building_id', 'created', 'description',\n",
    "       'display_address', 'features', 'latitude','listing_id', 'longitude',\n",
    "       'manager_id', 'photos', 'price', 'street_address', 'interest_level',\n",
    "       'distance_manh', 'distance_central_park', 'bronx', 'queens', 'brooklin_cometery', 'brooklin', 'clusters',\n",
    "       'num_features', 'num_description_words', 'created_year',\n",
    "       'created_month', 'created_day', 'created_hour', 'room_difference',\n",
    "       'total_rooms', 'price_per_room', 'subway_distance', \n",
    "        \"density\", \"price_latitude\", \"price_longtitude\", 'total_days', 'diff_rank', 'time_stamp', 'price0', \n",
    "             'price_per_bedroom', 'price_per_bathroom']\n",
    "\n",
    "\n",
    "\n",
    "list_test = ['bathrooms', 'bedrooms', 'building_id', 'created', 'description',\n",
    "       'display_address', 'features', 'latitude', 'listing_id', 'longitude',\n",
    "       'manager_id', 'photos', 'price', 'street_address',\n",
    "       'distance_manh', 'distance_central_park', 'bronx', 'queens', 'brooklin_cometery', 'brooklin', 'clusters',\n",
    "       'num_features', 'num_description_words', 'created_year',\n",
    "       'created_month', 'created_day', 'created_hour', 'room_difference',\n",
    "       'total_rooms', 'price_per_room', 'subway_distance', \n",
    "        \"density\",\n",
    "        \"price_latitude\", \"price_longtitude\", 'total_days', 'diff_rank', 'time_stamp', 'price0',\n",
    "            'price_per_bedroom', 'price_per_bathroom']\n",
    "\n",
    "train_df = train_df[list_feat]\n",
    "test_df = test_df[list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c3018e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Текстовые данные\n",
    "#Колонки для чистки текста\n",
    "cols_text = ['description', 'display_address', 'street_address', 'features']\n",
    "#Преобразуем в тип str\n",
    "train_df[cols_text] = train_df[cols_text].astype(str)\n",
    "\n",
    "test_df[cols_text] = test_df[cols_text].astype(str)\n",
    "\n",
    "#To lower case\n",
    "\n",
    "train_df[cols_text] = train_df[cols_text].apply(lambda x: x.str.lower())\n",
    "test_df[cols_text] = test_df[cols_text].apply(lambda x: x.str.lower())\n",
    "\n",
    "#Remove punctuation\n",
    "with_whitespace = ['&', '(', ')', \"-\", \"_\", ':', '=', '\"', ',']\n",
    "with_empty = ['.', \"'\", '`', '!', '*', '#', '/', '<', '>', 'br',\n",
    "              ';', '$', '%', '|', '+', '?']\n",
    "\n",
    "\n",
    "def replace_symbol(df, to_replace, replace_by):\n",
    "    for symbol in to_replace:\n",
    "        df = df.apply(lambda x: x.str.replace(symbol, replace_by, regex = True)) \n",
    "    return df\n",
    "\n",
    "train_df[cols_text] = replace_symbol(train_df[cols_text], with_whitespace, ' ')\n",
    "train_df[cols_text] = replace_symbol(train_df[cols_text], with_empty, '')\n",
    "\n",
    "test_df[cols_text] = replace_symbol(test_df[cols_text], with_whitespace, ' ')\n",
    "test_df[cols_text] = replace_symbol(test_df[cols_text], with_empty, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4466d9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ищу элементы в текстовых данных\n",
    "desc_feat = ['description', 'features']\n",
    "#ссылки\n",
    "train_df[desc_feat] = train_df[desc_feat].replace('\\swww.\\S*', ' weblink ', regex = True)\n",
    "#почты\n",
    "train_df[desc_feat] = train_df[desc_feat].replace('\\s\\S*@\\S*', ' emailaddress', regex = True)\n",
    "#время\n",
    "train_df[desc_feat] = train_df[desc_feat].replace('\\s\\d{1,2}\\s\\d\\d[ap]m', ' ampmtime', regex = True)\n",
    "#номера\n",
    "train_df[desc_feat] = train_df[desc_feat].replace('\\s\\d{2,4}\\s\\d{2,4}\\s\\d{2,4}', ' phonenumber', regex = True)\n",
    "\n",
    "\n",
    "test_df[desc_feat] = test_df[desc_feat].replace('\\swww.\\S*', ' weblink ', regex = True)\n",
    "#почты\n",
    "test_df[desc_feat] = test_df[desc_feat].replace('\\s\\S*@\\S*', ' emailaddress', regex = True)\n",
    "#timeвремя\n",
    "test_df[desc_feat] = test_df[desc_feat].replace('\\s\\d{1,2}\\s\\d\\d[ap]m', ' ampmtime', regex = True)\n",
    "#номера\n",
    "test_df[desc_feat] = test_df[desc_feat].replace('\\s\\d{2,4}\\s\\d{2,4}\\s\\d{2,4}', ' phonenumber', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ea2649c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чистка текста\n",
    "adr_feat = ['display_address', 'street_address']\n",
    "\n",
    "\n",
    "train_df[adr_feat] = train_df[adr_feat].replace(['\\sst\\s', '\\sst$'], ' street', regex = True)\n",
    "train_df[adr_feat] = train_df[adr_feat].replace(['\\save\\s', '\\save$'], ' avenue', regex = True)\n",
    "\n",
    "test_df[adr_feat] = test_df[adr_feat].replace(['\\sst\\s', '\\sst$'], ' street', regex = True)\n",
    "test_df[adr_feat] = test_df[adr_feat].replace(['\\save\\s', '\\save$'], ' avenue', regex = True)\n",
    "\n",
    "\n",
    "train_df[adr_feat] = train_df[adr_feat].replace(['\\se\\s', '^e\\s'], ' east ', regex = True)\n",
    "train_df[adr_feat] = train_df[adr_feat].replace(['\\sw\\s', '^w\\s'], ' west ', regex = True)\n",
    "\n",
    "test_df[adr_feat] = test_df[adr_feat].replace(['\\se\\s', '^e\\s'], ' east ', regex = True)\n",
    "test_df[adr_feat] =test_df[adr_feat].replace(['\\sw\\s', '^w\\s'], ' west ', regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "9ab954f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодирую признаки\n",
    "num_target = {'high':0, 'medium':1, 'low':2}\n",
    "train_df['interest_level'] = train_df['interest_level'].apply(lambda x: num_target[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "08fa101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4a06da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop('interest_level', axis=1)\n",
    "y = train_df['interest_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "aa22d2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "dc6d5b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "SEED = 42\n",
    "FOLDS = 7\n",
    "\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "32ddc814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.153494\n",
      "0:\tlearn: 0.9798318\ttest: 0.9809291\tbest: 0.9809291 (0)\ttotal: 223ms\tremaining: 3m 42s\n",
      "100:\tlearn: 0.5156126\ttest: 0.5304539\tbest: 0.5304539 (100)\ttotal: 5.03s\tremaining: 44.8s\n",
      "200:\tlearn: 0.4901054\ttest: 0.5232505\tbest: 0.5232505 (200)\ttotal: 9.05s\tremaining: 36s\n",
      "300:\tlearn: 0.4719124\ttest: 0.5194544\tbest: 0.5194544 (300)\ttotal: 13.7s\tremaining: 31.9s\n",
      "400:\tlearn: 0.4575862\ttest: 0.5172345\tbest: 0.5172345 (400)\ttotal: 17.5s\tremaining: 26.1s\n",
      "500:\tlearn: 0.4428320\ttest: 0.5160879\tbest: 0.5160811 (498)\ttotal: 21.4s\tremaining: 21.3s\n",
      "600:\tlearn: 0.4311557\ttest: 0.5159010\tbest: 0.5156582 (592)\ttotal: 25.2s\tremaining: 16.7s\n",
      "700:\tlearn: 0.4196606\ttest: 0.5157836\tbest: 0.5154752 (654)\ttotal: 29.1s\tremaining: 12.4s\n",
      "bestTest = 0.5154752124\n",
      "bestIteration = 654\n",
      "Shrink model to first 655 iterations.\n",
      "Learning rate set to 0.153494\n",
      "0:\tlearn: 0.9800798\ttest: 0.9791356\tbest: 0.9791356 (0)\ttotal: 85.5ms\tremaining: 1m 25s\n",
      "100:\tlearn: 0.5179548\ttest: 0.5292147\tbest: 0.5292147 (100)\ttotal: 5.57s\tremaining: 49.6s\n",
      "200:\tlearn: 0.4907700\ttest: 0.5217833\tbest: 0.5217833 (200)\ttotal: 10.1s\tremaining: 40.2s\n",
      "300:\tlearn: 0.4713348\ttest: 0.5187935\tbest: 0.5187935 (300)\ttotal: 14.1s\tremaining: 32.8s\n",
      "400:\tlearn: 0.4558022\ttest: 0.5165385\tbest: 0.5163559 (390)\ttotal: 18s\tremaining: 26.9s\n",
      "500:\tlearn: 0.4423367\ttest: 0.5154487\tbest: 0.5153386 (495)\ttotal: 21.9s\tremaining: 21.8s\n",
      "600:\tlearn: 0.4303481\ttest: 0.5147295\tbest: 0.5145569 (592)\ttotal: 25.9s\tremaining: 17.2s\n",
      "700:\tlearn: 0.4193992\ttest: 0.5138223\tbest: 0.5138223 (700)\ttotal: 29.7s\tremaining: 12.7s\n",
      "800:\tlearn: 0.4089392\ttest: 0.5137836\tbest: 0.5133448 (761)\ttotal: 33.5s\tremaining: 8.33s\n",
      "bestTest = 0.5133448076\n",
      "bestIteration = 761\n",
      "Shrink model to first 762 iterations.\n",
      "Learning rate set to 0.153495\n",
      "0:\tlearn: 0.9799161\ttest: 0.9798851\tbest: 0.9798851 (0)\ttotal: 140ms\tremaining: 2m 19s\n",
      "100:\tlearn: 0.5156836\ttest: 0.5375873\tbest: 0.5375873 (100)\ttotal: 5.18s\tremaining: 46.1s\n",
      "200:\tlearn: 0.4875561\ttest: 0.5300712\tbest: 0.5300518 (193)\ttotal: 9.39s\tremaining: 37.3s\n",
      "300:\tlearn: 0.4667033\ttest: 0.5267320\tbest: 0.5266605 (295)\ttotal: 13.5s\tremaining: 31.2s\n",
      "400:\tlearn: 0.4508985\ttest: 0.5250831\tbest: 0.5250831 (400)\ttotal: 17.3s\tremaining: 25.9s\n",
      "500:\tlearn: 0.4363670\ttest: 0.5240788\tbest: 0.5240154 (499)\ttotal: 21.3s\tremaining: 21.2s\n",
      "bestTest = 0.5240154034\n",
      "bestIteration = 499\n",
      "Shrink model to first 500 iterations.\n",
      "Learning rate set to 0.153495\n",
      "0:\tlearn: 0.9794737\ttest: 0.9802899\tbest: 0.9802899 (0)\ttotal: 217ms\tremaining: 3m 37s\n",
      "100:\tlearn: 0.5147824\ttest: 0.5333490\tbest: 0.5333415 (99)\ttotal: 5.14s\tremaining: 45.8s\n",
      "200:\tlearn: 0.4880024\ttest: 0.5260187\tbest: 0.5260187 (200)\ttotal: 9.75s\tremaining: 38.8s\n",
      "300:\tlearn: 0.4697462\ttest: 0.5233702\tbest: 0.5233446 (298)\ttotal: 14.3s\tremaining: 33.2s\n",
      "400:\tlearn: 0.4547661\ttest: 0.5222802\tbest: 0.5222802 (400)\ttotal: 18.2s\tremaining: 27.1s\n",
      "500:\tlearn: 0.4414919\ttest: 0.5209001\tbest: 0.5209001 (500)\ttotal: 22s\tremaining: 21.9s\n",
      "600:\tlearn: 0.4303480\ttest: 0.5192344\tbest: 0.5191976 (585)\ttotal: 25.7s\tremaining: 17.1s\n",
      "bestTest = 0.5186936226\n",
      "bestIteration = 645\n",
      "Shrink model to first 646 iterations.\n",
      "Learning rate set to 0.153495\n",
      "0:\tlearn: 0.9797168\ttest: 0.9789582\tbest: 0.9789582 (0)\ttotal: 279ms\tremaining: 4m 38s\n",
      "100:\tlearn: 0.5148089\ttest: 0.5318404\tbest: 0.5318404 (100)\ttotal: 4.89s\tremaining: 43.6s\n",
      "200:\tlearn: 0.4877040\ttest: 0.5240892\tbest: 0.5240892 (200)\ttotal: 8.85s\tremaining: 35.2s\n",
      "300:\tlearn: 0.4688296\ttest: 0.5215029\tbest: 0.5215029 (300)\ttotal: 12.6s\tremaining: 29.2s\n",
      "400:\tlearn: 0.4537777\ttest: 0.5192589\tbest: 0.5192536 (399)\ttotal: 16.3s\tremaining: 24.3s\n",
      "500:\tlearn: 0.4389402\ttest: 0.5165428\tbest: 0.5165428 (500)\ttotal: 20s\tremaining: 19.9s\n",
      "600:\tlearn: 0.4266970\ttest: 0.5158246\tbest: 0.5157395 (553)\ttotal: 23.6s\tremaining: 15.7s\n",
      "bestTest = 0.5157394517\n",
      "bestIteration = 553\n",
      "Shrink model to first 554 iterations.\n",
      "Learning rate set to 0.153495\n",
      "0:\tlearn: 0.9802182\ttest: 0.9788327\tbest: 0.9788327 (0)\ttotal: 234ms\tremaining: 3m 54s\n",
      "100:\tlearn: 0.5181646\ttest: 0.5277095\tbest: 0.5277095 (100)\ttotal: 4.9s\tremaining: 43.6s\n",
      "200:\tlearn: 0.4901424\ttest: 0.5194587\tbest: 0.5194587 (200)\ttotal: 8.93s\tremaining: 35.5s\n",
      "300:\tlearn: 0.4694987\ttest: 0.5169694\tbest: 0.5169694 (300)\ttotal: 13s\tremaining: 30.1s\n",
      "400:\tlearn: 0.4537264\ttest: 0.5158198\tbest: 0.5157810 (394)\ttotal: 16.8s\tremaining: 25.1s\n",
      "500:\tlearn: 0.4383971\ttest: 0.5138808\tbest: 0.5137516 (495)\ttotal: 20.7s\tremaining: 20.7s\n",
      "bestTest = 0.5137516276\n",
      "bestIteration = 495\n",
      "Shrink model to first 496 iterations.\n",
      "Learning rate set to 0.153495\n",
      "0:\tlearn: 0.9800504\ttest: 0.9802058\tbest: 0.9802058 (0)\ttotal: 280ms\tremaining: 4m 39s\n",
      "100:\tlearn: 0.5174755\ttest: 0.5291519\tbest: 0.5291505 (99)\ttotal: 5.11s\tremaining: 45.5s\n",
      "200:\tlearn: 0.4884249\ttest: 0.5191669\tbest: 0.5190888 (199)\ttotal: 9.19s\tremaining: 36.5s\n",
      "300:\tlearn: 0.4683063\ttest: 0.5157010\tbest: 0.5157010 (300)\ttotal: 13.1s\tremaining: 30.3s\n",
      "400:\tlearn: 0.4518495\ttest: 0.5142354\tbest: 0.5141022 (392)\ttotal: 17.1s\tremaining: 25.5s\n",
      "bestTest = 0.5141021512\n",
      "bestIteration = 392\n",
      "Shrink model to first 393 iterations.\n"
     ]
    }
   ],
   "source": [
    "# Кроссвалидация\n",
    "\n",
    "\n",
    "cv_test_preds = np.zeros((len(test_df), 3))\n",
    "\n",
    "cat_features = ['created_day', 'created_month','manager_id', 'building_id', 'display_address']\n",
    "text_features = ['description','street_address' , 'features']\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    X_train, y_train = X.iloc[train_idx, :], y[train_idx]\n",
    "    X_val, y_val = X.iloc[val_idx, :], y[val_idx]\n",
    "    \n",
    "    train = Pool(data=X_train, \n",
    "             label=y_train,            \n",
    "             feature_names=list(X_train.columns),\n",
    "             cat_features=cat_features,\n",
    "             text_features = text_features)\n",
    "\n",
    "    val = Pool(data=X_val, \n",
    "               label=y_val,\n",
    "               feature_names=list(X_val.columns),\n",
    "               cat_features=cat_features,\n",
    "               text_features = text_features)\n",
    "\n",
    "    model = CatBoostClassifier(random_seed = 17,\n",
    "                              iterations = 1000,\n",
    "                            thread_count = -1, \n",
    "                            verbose = 100,\n",
    "                              bootstrap_type=\"Bernoulli\",\n",
    "                            loss_function='MultiClass',\n",
    "                          task_type=\"GPU\")\n",
    "    \n",
    "    model.fit(train,\n",
    "            early_stopping_rounds=50,\n",
    "             eval_set=val,\n",
    "             use_best_model=True)\n",
    "\n",
    "    Test = Pool(data=test_df,\n",
    "            cat_features=cat_features,\n",
    "            text_features = text_features)\n",
    "    \n",
    "    preds = model.predict_proba(Test)\n",
    "    \n",
    "    \n",
    "    cv_test_preds += model.predict_proba(Test) / FOLDS\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "5847ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(cv_test_preds)\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test_df.listing_id.values\n",
    "sub['high'] = predictions[0]\n",
    "sub['medium'] = predictions[1]\n",
    "sub['low'] = predictions[2]\n",
    "\n",
    "sub.to_csv('guzeev_cross_newpr_7_fold_new_room.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2584a034",
   "metadata": {},
   "source": [
    "### Важность фич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b808b536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Id</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>description</td>\n",
       "      <td>15.670987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manager_id</td>\n",
       "      <td>9.178532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>features</td>\n",
       "      <td>8.972821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>price_per_room</td>\n",
       "      <td>7.732289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>building_id</td>\n",
       "      <td>6.692271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>price_longtitude</td>\n",
       "      <td>4.995111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time_stamp</td>\n",
       "      <td>4.764185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>price_per_bedroom</td>\n",
       "      <td>4.432489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>distance_manh</td>\n",
       "      <td>3.710011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>price</td>\n",
       "      <td>3.464551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>price_per_bathroom</td>\n",
       "      <td>3.005474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>created_hour</td>\n",
       "      <td>2.994290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>longitude</td>\n",
       "      <td>2.849694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>listing_id</td>\n",
       "      <td>2.492669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>distance_central_park</td>\n",
       "      <td>2.189209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>num_features</td>\n",
       "      <td>1.844696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>photos</td>\n",
       "      <td>1.713378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>price_latitude</td>\n",
       "      <td>1.568151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>street_address</td>\n",
       "      <td>1.404577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>1.128635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>room_difference</td>\n",
       "      <td>1.123948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.985964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>display_address</td>\n",
       "      <td>0.797545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>brooklin</td>\n",
       "      <td>0.796246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>subway_distance</td>\n",
       "      <td>0.723443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>brooklin_cometery</td>\n",
       "      <td>0.701003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>0.509627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>created</td>\n",
       "      <td>0.502826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>queens</td>\n",
       "      <td>0.475094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>density</td>\n",
       "      <td>0.459022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bronx</td>\n",
       "      <td>0.404844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>total_days</td>\n",
       "      <td>0.366941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>num_description_words</td>\n",
       "      <td>0.362065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>created_day</td>\n",
       "      <td>0.335592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>diff_rank</td>\n",
       "      <td>0.326414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>total_rooms</td>\n",
       "      <td>0.228952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>price0</td>\n",
       "      <td>0.056003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>created_month</td>\n",
       "      <td>0.040452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>clusters</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>created_year</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature Id  Importances\n",
       "0             description    15.670987\n",
       "1              manager_id     9.178532\n",
       "2                features     8.972821\n",
       "3          price_per_room     7.732289\n",
       "4             building_id     6.692271\n",
       "5        price_longtitude     4.995111\n",
       "6              time_stamp     4.764185\n",
       "7       price_per_bedroom     4.432489\n",
       "8           distance_manh     3.710011\n",
       "9                   price     3.464551\n",
       "10     price_per_bathroom     3.005474\n",
       "11           created_hour     2.994290\n",
       "12              longitude     2.849694\n",
       "13             listing_id     2.492669\n",
       "14  distance_central_park     2.189209\n",
       "15           num_features     1.844696\n",
       "16                 photos     1.713378\n",
       "17         price_latitude     1.568151\n",
       "18         street_address     1.404577\n",
       "19              bathrooms     1.128635\n",
       "20        room_difference     1.123948\n",
       "21               latitude     0.985964\n",
       "22        display_address     0.797545\n",
       "23               brooklin     0.796246\n",
       "24        subway_distance     0.723443\n",
       "25      brooklin_cometery     0.701003\n",
       "26               bedrooms     0.509627\n",
       "27                created     0.502826\n",
       "28                 queens     0.475094\n",
       "29                density     0.459022\n",
       "30                  bronx     0.404844\n",
       "31             total_days     0.366941\n",
       "32  num_description_words     0.362065\n",
       "33            created_day     0.335592\n",
       "34              diff_rank     0.326414\n",
       "35            total_rooms     0.228952\n",
       "36                 price0     0.056003\n",
       "37          created_month     0.040452\n",
       "38               clusters     0.000000\n",
       "39           created_year     0.000000"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138b9f29",
   "metadata": {},
   "source": [
    "##### 1.Не смотря на то, что даные более менее чистые (не имеют пропусков). Данные содержат ошибки:\n",
    " * Нулевое количество ванных комнат\n",
    " * Экстремальное количество ванных комнат 112 и 20 (при заполнении полагаю имелось в виду 1 и 2)\n",
    " * География по координатам содержала ошибочные данные. Также были совсем другие регионы\n",
    " * Цены тоже имели ошибочные данные или почти нулевая цена или заоблачная\n",
    " \n",
    "##### 2. Идеи по Фич Инжинирингу:\n",
    " * Создание фич из отличия количества спален и ванных комнат\n",
    " * Цена за комнату\n",
    " * Цена за спальню и.т.д\n",
    " * Можно сделать регрессор зависмости ванных комнат и спален и найти отношение к реальной цене\n",
    " * Была идея разделить признаки столбец `features` по темам, разбивка на семь тем результатов не принесла, тогда написал функцию по оптимальному количеству тем, но функция работала долго (не дождался).\n",
    " * Фичи по дистанции от центральных мест дало прирост. За центральные места были взяты: финансовый квартал Манхэтэна и центральный парк\n",
    " * Одной из фич была кластеризация по координатам. Предполагал, что число кластеров должно быть равно числу станций метро=476, но лучше результат показал небольшое число кластеров 2-3. Тут представлена кластеризация Kmeans, но таже делал HDBSCAN\n",
    " * Как числовые данные были взяты количество признаков или слов, также и с фото\n",
    " \n",
    "#### Модель\n",
    " * Настройку гиперпараметров не делал. Метрики классификации не показывал. Интересовал score в kaggle\n",
    " * Чистка TRAIN и TEST не принесла результатов, лучше модель работает на сырых данных\n",
    " * Или по экстремальным значениям данных извлекать больше сторонней информации. Например, пропущенные координаты можно было восстановить по адресу. Одной из фич можно было сделать расстояние от метро.\n",
    " * Конечный SCORE получился 0.54791\n",
    " \n",
    " * ***********\n",
    " * Catboost показал примерно такие же результаты\n",
    " * Фича привязка к метро, и дистанцию к самому бедному району (БРОНКС) дала прирост к SCORE около 0.5%\n",
    " * Конечный SCORE составил `0.54515` был `0.54834`\n",
    " * ***********\n",
    " #### ОБНОВЛЕНО 12.12.2022\n",
    " \n",
    " 1. Были взяты некоторые фичи с этого кернела (указаны в комментариях)\n",
    " 2. Хорошо увеличил скор при использовании времени создания картинок (торрент файл)\n",
    " 3. Score увеличился при использовании catboost\n",
    " 4. Использование коэффициента вариации (что-то похожее) при кодировании менеджеров для модели не принесли результатов\n",
    " 5. Чистка координат по граничным зонам принесла результаты\n",
    " 6. Границу для чистки по price необходимо \"подлавливать\"\n",
    " 7. Привязка к другим районам дала прибавку к score. Где-то привязывал к кладбищу.\n",
    " \n",
    " ###### Возможные дальнейшие шаги:\n",
    " 1. Сделать новые фичи на основе manager_id, building_id, итд. То есть копать больше в сторону менеджеров, building_id итд\n",
    " 2. Делал по большей части в Catboost, так как Catboost сам кодирует текстовые и категориальные данные.\n",
    " 3. Хотел затюнить модель `grid_search`, но даже с хорошей видеокартой считает долго.Не дождался. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a8e45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
